{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faster-whisper@ https://github.com/nyanta012/faster-whisper/archive/refs/heads/master.tar.gz\n",
      "  Using cached https://github.com/nyanta012/faster-whisper/archive/refs/heads/master.tar.gz\n",
      "Collecting av==10.*\n",
      "  Using cached av-10.0.0-cp310-cp310-win_amd64.whl (25.3 MB)\n",
      "Collecting ctranslate2<4,>=3.9\n",
      "  Using cached ctranslate2-3.17.1-cp310-cp310-win_amd64.whl (20.1 MB)\n",
      "Collecting tokenizers==0.13.*\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.25.1-cp310-cp310-win_amd64.whl (15.0 MB)\n",
      "Collecting pyyaml<7,>=5.3\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-win_amd64.whl (145 kB)\n",
      "Using legacy 'setup.py install' for faster-whisper, since package 'wheel' is not installed.\n",
      "Installing collected packages: pyyaml, numpy, tokenizers, ctranslate2, av, faster-whisper\n",
      "    Running setup.py install for faster-whisper: started\n",
      "    Running setup.py install for faster-whisper: finished with status 'done'\n",
      "Successfully installed av-10.0.0 ctranslate2-3.17.1 faster-whisper-0.1.0 numpy-1.25.1 pyyaml-6.0.1 tokenizers-0.13.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\python\\faster_whisper\\faster\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.27.2\n",
      "  Using cached transformers-4.27.2-py3-none-any.whl (6.8 MB)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in .\\faster\\lib\\site-packages (from transformers==4.27.2) (0.13.3)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.6.3-cp310-cp310-win_amd64.whl (268 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in .\\faster\\lib\\site-packages (from transformers==4.27.2) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\faster\\lib\\site-packages (from transformers==4.27.2) (23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in .\\faster\\lib\\site-packages (from transformers==4.27.2) (1.25.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: colorama in .\\faster\\lib\\site-packages (from tqdm>=4.27->transformers==4.27.2) (0.4.6)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.2.0-cp310-cp310-win_amd64.whl (96 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, typing-extensions, tqdm, requests, fsspec, filelock, regex, huggingface-hub, transformers\n",
      "Successfully installed certifi-2023.7.22 charset-normalizer-3.2.0 filelock-3.12.2 fsspec-2023.6.0 huggingface-hub-0.16.4 idna-3.4 regex-2023.6.3 requests-2.31.0 tqdm-4.65.0 transformers-4.27.2 typing-extensions-4.7.1 urllib3-2.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\python\\faster_whisper\\faster\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install \"faster-whisper @ https://github.com/nyanta012/faster-whisper/archive/refs/heads/master.tar.gz\"\n",
    "!pip install transformers==4.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srt file を作成するための関数\n",
    "def create_srt_file(file_name=\"transcribe\", results=None, fast_whisper=True):\n",
    "    with open(f\"{file_name}.srt\", mode=\"w\") as f:\n",
    "        for index, _dict in enumerate(results):\n",
    "            if fast_whisper:\n",
    "              start_time = _dict[0] # start\n",
    "              end_time = _dict[1] # end\n",
    "              text = _dict[2] # text\n",
    "            else:\n",
    "              start_time = _dict[\"start\"]\n",
    "              end_time = _dict[\"end\"]\n",
    "              text = _dict[\"text\"]\n",
    "            s_h, e_h = int(start_time//(60 * 60)), int(end_time//(60 * 60))\n",
    "            s_m, e_m = int((start_time % (60 * 60))//60), int((end_time % (60 * 60))//60)\n",
    "            s_s, e_s = int(start_time % 60), int(end_time % 60)\n",
    "            f.write(f'{index+1}\\n{s_h:02}:{s_m:02}:{s_s:02},000 --> {e_h:02}:{e_m:02}:{e_s:02},000\\n{text}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['faster', 'faster_whisper_v3.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# アップロード後、下記を実行することで、ファイル名を取得\n",
    "import os\n",
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アップロードしたファイル名を設定(拡張子まで含める)\n",
    "file_name = \"サンプル動画.mkv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/nyanta012/whisper_v2.git\n",
      "  Cloning https://github.com/nyanta012/whisper_v2.git to c:\\users\\w83s8\\appdata\\local\\temp\\pip-req-build-kmatjab7\n",
      "  Resolved https://github.com/nyanta012/whisper_v2.git to commit 6dea21fd7f7253bfe450f1e2512a0fe47ee2d258\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting ffmpeg-python==0.2.0\n",
      "  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.0.1-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "Requirement already satisfied: tqdm in .\\faster\\lib\\site-packages (from openai-whisper==20230314) (4.65.0)\n",
      "Collecting numba\n",
      "  Using cached numba-0.57.1-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: numpy in .\\faster\\lib\\site-packages (from openai-whisper==20230314) (1.25.1)\n",
      "Collecting more-itertools\n",
      "  Using cached more_itertools-10.0.0-py3-none-any.whl (55 kB)\n",
      "Collecting tiktoken==0.3.1\n",
      "  Using cached tiktoken-0.3.1-cp310-cp310-win_amd64.whl (581 kB)\n",
      "Collecting future\n",
      "  Using cached future-0.18.3-py3-none-any.whl\n",
      "Requirement already satisfied: regex>=2022.1.18 in .\\faster\\lib\\site-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in .\\faster\\lib\\site-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\faster\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\faster\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\faster\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\faster\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2023.7.22)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0\n",
      "  Using cached llvmlite-0.40.1-cp310-cp310-win_amd64.whl (27.7 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.4-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Requirement already satisfied: filelock in .\\faster\\lib\\site-packages (from torch->openai-whisper==20230314) (3.12.2)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: typing-extensions in .\\faster\\lib\\site-packages (from torch->openai-whisper==20230314) (4.7.1)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.3-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: colorama in .\\faster\\lib\\site-packages (from tqdm->openai-whisper==20230314) (0.4.6)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (PEP 517): started\n",
      "  Building wheel for openai-whisper (PEP 517): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=806216 sha256=e9e178a8b4ea6955925ffcd83c371a4d1890eb0e537215d52cb2d2e76dbba6db\n",
      "  Stored in directory: C:\\Users\\w83s8\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-2vp9591t\\wheels\\74\\e2\\8d\\848ca2017017fee18688ba1ae3aa949dcecf53ee56c1c8f8d2\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: mpmath, MarkupSafe, sympy, numpy, networkx, llvmlite, jinja2, future, torch, tiktoken, numba, more-itertools, ffmpeg-python, openai-whisper\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.1\n",
      "    Uninstalling numpy-1.25.1:\n",
      "      Successfully uninstalled numpy-1.25.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/nyanta012/whisper_v2.git 'C:\\Users\\w83s8\\AppData\\Local\\Temp\\pip-req-build-kmatjab7'\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] 存取被拒。: 'C:\\\\python\\\\faster_whisper\\\\faster\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas64__v0.3.23-gcc_10_3_0.dll'\n",
      "Check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 21.2.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\python\\faster_whisper\\faster\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/nyanta012/whisper_v2.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'whisper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwhisper\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model \u001b[39m=\u001b[39m whisper\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39mlarge-v2\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'whisper'"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"large-v2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
